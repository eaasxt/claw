version: "3.8"
services:
  fastapi:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - .:/app
    environment:
      - MODEL_PATH=models/mistral-7b-instruct-v0.2.Q4_K_M.gguf

  llama:
    image: ghcr.io/ggerganov/llama.cpp:server
    command: ["--model", "/models/mistral-7b-instruct-v0.2.Q4_K_M.gguf"]
    volumes:
      - ./models:/models
    ports:
      - "8001:8000"
